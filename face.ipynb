{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhwCzWbku4S_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(title,img):\n",
        "  plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "  plt.title(title)"
      ],
      "metadata": {
        "id": "gK_wVY1-wPtr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_dir = \"/content/drive/MyDrive/0-myComputerVisionProjects/siamese_dataset\"\n",
        "\n",
        "subdirs = [subdir for subdir in os.listdir(face_dir) if os.path.isdir(os.path.join(face_dir, subdir))]"
      ],
      "metadata": {
        "id": "VDyoGRUJwPwV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subdirs"
      ],
      "metadata": {
        "id": "xbZeGdqmwPys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e3a36f-d831-489f-9ae3-517068b844f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Depika',\n",
              " 'messi',\n",
              " 'Ranbir',\n",
              " 'Nora',\n",
              " 'Urvashi',\n",
              " 'gigi_hadid',\n",
              " 'bella_hadid',\n",
              " 'lana_del_rey']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image pairs"
      ],
      "metadata": {
        "id": "VM9ixAMXweV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 224\n",
        "\n",
        "# Dictionary to store face images for each person\n",
        "face_dict = {}\n",
        "\n",
        "# Load face images for each person into the face_dict dictionary\n",
        "for subdir in subdirs:\n",
        "    face_dict[subdir] = []\n",
        "    subdir_path = os.path.join(face_dir, subdir)\n",
        "    for filename in os.listdir(subdir_path):\n",
        "        image_path = os.path.join(subdir_path, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = image.astype('float32')\n",
        "        image = cv2.resize(image,(size,size))\n",
        "        image = image / 255.\n",
        "\n",
        "        face_dict[subdir].append(image)"
      ],
      "metadata": {
        "id": "n8j2qCJnwP1y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def make_pairs():\n",
        "\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    # Same pairs\n",
        "    same_pairs = []\n",
        "    for person in face_dict.keys():\n",
        "        for i in range(len(face_dict[person])):\n",
        "            for j in range(i+1, len(face_dict[person])):\n",
        "                same_pairs.append([face_dict[person][i], face_dict[person][j]])\n",
        "\n",
        "    # Different pairs\n",
        "    diff_pairs = []\n",
        "    for i in range(len(subdirs)):\n",
        "        for j in range(i+1, len(subdirs)):\n",
        "            for k in range(len(face_dict[subdirs[i]])):\n",
        "                for l in range(len(face_dict[subdirs[j]])):\n",
        "                    diff_pairs.append([face_dict[subdirs[i]][k], face_dict[subdirs[j]][l]])\n",
        "\n",
        "    # Sample the same and different pairs to have the same number of samples\n",
        "    n_pairs = min(len(same_pairs), len(diff_pairs))\n",
        "    same_pairs = random.sample(same_pairs, n_pairs)\n",
        "    diff_pairs = random.sample(diff_pairs, n_pairs)\n",
        "\n",
        "    # Combine same and different pairs and labels\n",
        "    pairs = same_pairs + diff_pairs\n",
        "    labels = [1]*n_pairs + [0]*n_pairs\n",
        "\n",
        "    return (np.array(pairs), np.array(labels))\n"
      ],
      "metadata": {
        "id": "5O9jDOrPzdDY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(pairs , labels) = make_pairs() "
      ],
      "metadata": {
        "id": "iiQVKK0J4XtE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yy9Vzp9xZlq",
        "outputId": "c59327bc-22b5-483c-99a7-e65ece67ea70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(870, 2, 224, 224, 3)\n",
            "(870,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_1 = np.count_nonzero(labels == 1)\n",
        "count_0 = np.count_nonzero(labels == 0)\n",
        "print(count_1)\n",
        "print(count_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqhTiFNFzjzY",
        "outputId": "d1dae605-99dd-4843-a1a2-1a8da884df19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435\n",
            "435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imshow('d',pairs[50,1])"
      ],
      "metadata": {
        "id": "3KyVEh0VJj6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow('d',pairs[50,0])"
      ],
      "metadata": {
        "id": "t47W9NRlJnok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0pK_y-9Jr7D",
        "outputId": "5348ba21-31a0-4c6e-c2e6-e47c255f868e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_pairs , val_pairs , train_labels , val_labels = train_test_split(pairs ,labels , test_size = 0.3)"
      ],
      "metadata": {
        "id": "CQut7FjKwgU_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_labels.shape)\n",
        "print(val_pairs.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_pairs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXuM439xz_Qs",
        "outputId": "76b0c235-b152-48b3-afd7-20af1414d647"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(261,)\n",
            "(261, 2, 224, 224, 3)\n",
            "(609,)\n",
            "(609, 2, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Siamese"
      ],
      "metadata": {
        "id": "P8qFMrskx3Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y, preds, margin=1):\n",
        " # cast the true class label data type to the predicted class label data type \n",
        " y = tf.cast(y, preds.dtype)\n",
        " # calculate the contrastive loss between the true labels and the predicted labels\n",
        " squaredPreds = K.square(preds)\n",
        " squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        " loss = 1-K.mean(y * squaredPreds + (1 - y) * squaredMargin) #1-\n",
        " return loss\n",
        " "
      ],
      "metadata": {
        "id": "jjYRsXuf5kyR"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def euclidean_distance(vectors):\n",
        "    # unpack the vectors into separate lists\n",
        "    (featsA, featsB) = vectors\n",
        "    # compute the sum of squared distances between the vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
        "    # return the euclidean distance between the vectors\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "metadata": {
        "id": "2buVOcEpxx1M"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,ZeroPadding2D,GlobalAveragePooling2D\n",
        "from keras.layers import Input, Lambda\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "v9M0An8ByIaP"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (224,224,3)"
      ],
      "metadata": {
        "id": "G_6eTMnkyWoE"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First network"
      ],
      "metadata": {
        "id": "BANzmryWFBVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning VGG19 for sisters network"
      ],
      "metadata": {
        "id": "3d9NOekQT2mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg19 import preprocess_input"
      ],
      "metadata": {
        "id": "tGTVlxnKGdNl"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_siamese_nn(shape, embedding=64, fineTune=False):\n",
        "    inputs = tf.keras.layers.Input(shape)\n",
        "    preprocess_fn = preprocess_input\n",
        "    base_model = tf.keras.applications.vgg19.VGG19(input_shape=shape, include_top=False, weights='imagenet')\n",
        "    \n",
        "    if fineTune==False:\n",
        "        base_model.trainable=False\n",
        "    else:\n",
        "        base_model.trainable = True\n",
        "        # Fine-tune from this layer onwards\n",
        "        fine_tune_at = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "        for layer in base_model.layers[:fine_tune_at]:\n",
        "          layer.trainable =  False\n",
        "          \n",
        "    x=base_model(inputs)\n",
        "    x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    outputs=tf.keras.layers.Dense(embedding)(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "gyyxO7t9xx6R"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_model=tf_siamese_nn(IMG_SHAPE,64 , True) \n",
        "first_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtQak0O0-Sxy",
        "outputId": "ff478cef-6eef-443e-b8fd-f684dffacbfc"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
            "                                                                 \n",
            " global_average_pooling2d_6   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,057,216\n",
            "Trainable params: 2,392,640\n",
            "Non-trainable params: 17,664,576\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
        "img2 =  tf.keras.layers.Input( shape=IMG_SHAPE)\n",
        "featureExtractor = tf_siamese_nn(IMG_SHAPE)\n",
        "featsA = featureExtractor(img1)\n",
        "featsB = featureExtractor(img2)"
      ],
      "metadata": {
        "id": "JUArHRWzxyA-"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])"
      ],
      "metadata": {
        "id": "jU1MPe1QwgXn"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = tf.keras.Model(inputs=[img1, img2], outputs=outputs)"
      ],
      "metadata": {
        "id": "QPgj4_QswP4i"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=contrastive_loss, optimizer=Adam(lr = 0.001), metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jVNJYQQKyuIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# early_stop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "q_wpmzJe6UmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(filepath='/content/drive/MyDrive/0-myComputerVisionProjects/my_model.h5', save_weights_only=True)\n"
      ],
      "metadata": {
        "id": "yGNN8bCygfej"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    [train_pairs[:, 0], train_pairs[:, 1]], train_labels[:],\n",
        "    validation_data=([val_pairs[:, 0], val_pairs[:, 1]], val_labels[:]),\n",
        "    batch_size=8, #32\n",
        "    epochs=100,\n",
        "    shuffle = True,\n",
        "    callbacks=[checkpoint_callback]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "FDkg-cbsyuMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Losses',size = 20)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VdZ4SqDb5SmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracies',size = 20)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nG_Z2eGMVECr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('')"
      ],
      "metadata": {
        "id": "yYBAVYYHRVjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second network"
      ],
      "metadata": {
        "id": "IJOu5e_KE8h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_siamese_model(inputShape, embeddingDim=48): #embedding_dim = 48\n",
        "\t# specify the inputs for the feature extractor network\n",
        "    inputs = Input(inputShape)\n",
        "    # define the first set of CONV => RELU => POOL => DROPOUT layers\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    # second set of CONV => RELU => POOL => DROPOUT layers\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    # third set of CONV => RELU => POOL => DROPOUT layers\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    # prepare the final outputs\n",
        "    pooledOutput = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(embeddingDim)(pooledOutput)\n",
        "    # build the model\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    # return the model to the calling function\n",
        "    return model"
      ],
      "metadata": {
        "id": "r9i4SlSVQDjg"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (size,size,3)"
      ],
      "metadata": {
        "id": "T3LGpSEAGLIe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgA = Input(shape=IMG_SHAPE)\n",
        "imgB = Input(shape=IMG_SHAPE)\n",
        "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)\n",
        "# finally, construct the siamese network\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "siamese_model = Model(inputs=[imgA, imgB], outputs=distance)"
      ],
      "metadata": {
        "id": "gEnJEKsgEih6"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.compile(loss=contrastive_loss, optimizer=Adam(lr=0.001), metrics=[\"accuracy\"])\n",
        "siamese_model.summary()"
      ],
      "metadata": {
        "id": "QY2yE6B8DuFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = siamese_model.fit(\n",
        "    [train_pairs[:, 0], train_pairs[:, 1]], train_labels,\n",
        "    validation_data=([val_pairs[:, 0], val_pairs[:, 1]], val_labels),\n",
        "    batch_size=8, \n",
        "    epochs=100\n",
        "    )"
      ],
      "metadata": {
        "id": "1Xi-oNX1FaDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# siamese_model.save('/content/drive/MyDrive/0-myComputerVisionProjects/siamese.h5')"
      ],
      "metadata": {
        "id": "67aiabSNMJPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third model"
      ],
      "metadata": {
        "id": "E1QbUuY3rlCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "my_model = load_model('/content/drive/MyDrive/0-myComputerVisionProjects/face.h5')"
      ],
      "metadata": {
        "id": "JhWUa_pfrm1e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.summary()"
      ],
      "metadata": {
        "id": "SudgMgrYztxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def siamese(shape,embedding=128):\n",
        "  # Get the first 3 layers from model1\n",
        "  layers_to_copy = my_model.layers[:4]\n",
        "\n",
        "  # Create a new model with the same input as model2\n",
        "  input_layer = my_model.input\n",
        "  output = input_layer\n",
        "\n",
        "  # Add the first 4 layers from my_model to the new model\n",
        "  for layer in layers_to_copy:\n",
        "      output = layer(output)\n",
        "\n",
        "  # Create a new model with the copied layers and the remaining layers of model2\n",
        "  new_model = Model(inputs=input_layer, outputs=output)\n",
        "  for layer in new_model.layers:\n",
        "        layer.trainable = False\n",
        "  inputs = tf.keras.layers.Input(shape)\n",
        "\n",
        "  x = new_model(inputs)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = tf.keras.layers.MaxPool2D(2)(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = tf.keras.layers.MaxPool2D(2)(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "  outputs=tf.keras.layers.Dense(embedding)(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "qhvUJt1xz9F5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_model = siamese(IMG_SHAPE,128) #64\n",
        "third_model.summary()"
      ],
      "metadata": {
        "id": "J2Csi-Wm0tg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = tf.keras.layers.Input(shape=IMG_SHAPE)\n",
        "img2 =  tf.keras.layers.Input( shape=IMG_SHAPE)\n",
        "featureExtractor = siamese(IMG_SHAPE)\n",
        "featsA = featureExtractor(img1)\n",
        "featsB = featureExtractor(img2)"
      ],
      "metadata": {
        "id": "OVB6ijkU19pF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])"
      ],
      "metadata": {
        "id": "iWm8H3IY2AuQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "final_model = tf.keras.Model(inputs=[img1, img2], outputs=outputs)"
      ],
      "metadata": {
        "id": "x7Yhve4A2Axi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.summary()"
      ],
      "metadata": {
        "id": "Csi1Y0EZ2A3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning"
      ],
      "metadata": {
        "id": "rs32u0p4sHYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def siamese_nn(shape, embedding=128): #fineTune =  False\n",
        "#     inputs = tf.keras.layers.Input(shape)\n",
        "#     base_model = my_model\n",
        "#     # Freeze all layers in the pre-trained model\n",
        "#     for layer in base_model.layers[:-1]:\n",
        "#        layer.trainable = False\n",
        "#     # Add AverageGlobalPooling layer\n",
        "#     x=base_model(inputs)\n",
        "#     # x = base_model.output\n",
        "#     # x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "#     outputs=tf.keras.layers.Dense(embedding)(x)\n",
        "#     model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "#     return model"
      ],
      "metadata": {
        "id": "ZY0TirIQsGy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.compile(loss=\"binary_crossentropy\",optimizer=Adam(0.001),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EWSsavMdvqgF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.summary()"
      ],
      "metadata": {
        "id": "KCeVU1Hu0CHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "IL81VGCyvqob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = final_model.fit(\n",
        "    [train_pairs[:, 0], train_pairs[:, 1]], train_labels,\n",
        "    validation_data=([val_pairs[:, 0], val_pairs[:, 1]], val_labels),\n",
        "    batch_size=8, \n",
        "    epochs=100,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "0WRkX5Jzvhw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0646ca4-e8c9-473e-e419-620a9c5229c7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 65s 832ms/step - loss: 0.6908 - accuracy: 0.5041 - val_loss: 0.6895 - val_accuracy: 0.5019\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 64s 841ms/step - loss: 0.6861 - accuracy: 0.5057 - val_loss: 0.6841 - val_accuracy: 0.4943\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.6485 - accuracy: 0.5090 - val_loss: 0.5911 - val_accuracy: 0.6169\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 62s 806ms/step - loss: 0.5843 - accuracy: 0.6355 - val_loss: 0.5743 - val_accuracy: 0.6897\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 63s 820ms/step - loss: 0.5706 - accuracy: 0.7028 - val_loss: 0.5601 - val_accuracy: 0.7778\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 63s 818ms/step - loss: 0.5560 - accuracy: 0.7471 - val_loss: 0.5528 - val_accuracy: 0.7280\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 65s 845ms/step - loss: 0.5408 - accuracy: 0.7685 - val_loss: 0.5354 - val_accuracy: 0.7701\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 65s 848ms/step - loss: 0.5247 - accuracy: 0.7734 - val_loss: 0.5183 - val_accuracy: 0.7893\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 64s 827ms/step - loss: 0.5090 - accuracy: 0.7882 - val_loss: 0.5136 - val_accuracy: 0.7816\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 62s 816ms/step - loss: 0.4887 - accuracy: 0.8128 - val_loss: 0.5089 - val_accuracy: 0.7816\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 54s 706ms/step - loss: 0.4677 - accuracy: 0.8128 - val_loss: 0.4899 - val_accuracy: 0.8046\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 56s 724ms/step - loss: 0.4718 - accuracy: 0.8112 - val_loss: 0.5029 - val_accuracy: 0.7778\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 65s 848ms/step - loss: 0.4515 - accuracy: 0.8259 - val_loss: 0.4734 - val_accuracy: 0.8008\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 65s 847ms/step - loss: 0.4355 - accuracy: 0.8407 - val_loss: 0.4560 - val_accuracy: 0.8352\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 64s 828ms/step - loss: 0.4257 - accuracy: 0.8571 - val_loss: 0.4411 - val_accuracy: 0.8659\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 54s 699ms/step - loss: 0.4098 - accuracy: 0.8768 - val_loss: 0.4339 - val_accuracy: 0.8352\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 64s 831ms/step - loss: 0.4111 - accuracy: 0.8539 - val_loss: 0.4224 - val_accuracy: 0.8506\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 62s 814ms/step - loss: 0.3954 - accuracy: 0.8637 - val_loss: 0.4418 - val_accuracy: 0.7893\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 55s 724ms/step - loss: 0.3791 - accuracy: 0.9031 - val_loss: 0.4076 - val_accuracy: 0.8544\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 62s 809ms/step - loss: 0.3721 - accuracy: 0.8900 - val_loss: 0.4034 - val_accuracy: 0.8391\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 63s 819ms/step - loss: 0.3537 - accuracy: 0.9015 - val_loss: 0.3838 - val_accuracy: 0.8621\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 63s 823ms/step - loss: 0.3453 - accuracy: 0.9113 - val_loss: 0.3830 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 64s 830ms/step - loss: 0.3454 - accuracy: 0.9113 - val_loss: 0.3513 - val_accuracy: 0.9157\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 64s 834ms/step - loss: 0.3341 - accuracy: 0.9130 - val_loss: 0.3690 - val_accuracy: 0.8851\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 65s 845ms/step - loss: 0.3065 - accuracy: 0.9261 - val_loss: 0.3260 - val_accuracy: 0.9349\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 65s 847ms/step - loss: 0.3036 - accuracy: 0.9245 - val_loss: 0.3338 - val_accuracy: 0.9004\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 64s 833ms/step - loss: 0.3028 - accuracy: 0.9294 - val_loss: 0.3085 - val_accuracy: 0.9540\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 65s 850ms/step - loss: 0.2801 - accuracy: 0.9475 - val_loss: 0.2868 - val_accuracy: 0.9349\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 65s 852ms/step - loss: 0.2737 - accuracy: 0.9475 - val_loss: 0.3141 - val_accuracy: 0.9157\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 54s 696ms/step - loss: 0.3004 - accuracy: 0.9163 - val_loss: 0.2839 - val_accuracy: 0.9464\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 65s 845ms/step - loss: 0.2619 - accuracy: 0.9507 - val_loss: 0.2788 - val_accuracy: 0.9502\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 55s 712ms/step - loss: 0.2540 - accuracy: 0.9458 - val_loss: 0.2521 - val_accuracy: 0.9579\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 65s 846ms/step - loss: 0.2428 - accuracy: 0.9622 - val_loss: 0.2565 - val_accuracy: 0.9464\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 63s 819ms/step - loss: 0.2592 - accuracy: 0.9491 - val_loss: 0.2886 - val_accuracy: 0.9387\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 62s 803ms/step - loss: 0.2410 - accuracy: 0.9475 - val_loss: 0.2490 - val_accuracy: 0.9464\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 61s 791ms/step - loss: 0.2406 - accuracy: 0.9491 - val_loss: 0.2330 - val_accuracy: 0.9464\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 55s 718ms/step - loss: 0.2442 - accuracy: 0.9409 - val_loss: 0.2439 - val_accuracy: 0.9502\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 57s 750ms/step - loss: 0.2173 - accuracy: 0.9622 - val_loss: 0.2367 - val_accuracy: 0.9617\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 61s 802ms/step - loss: 0.2116 - accuracy: 0.9622 - val_loss: 0.2369 - val_accuracy: 0.9464\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 56s 732ms/step - loss: 0.2263 - accuracy: 0.9557 - val_loss: 0.2442 - val_accuracy: 0.9234\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.2111 - accuracy: 0.9557 - val_loss: 0.2188 - val_accuracy: 0.9540\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 65s 845ms/step - loss: 0.2346 - accuracy: 0.9392 - val_loss: 0.2356 - val_accuracy: 0.9617\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 54s 711ms/step - loss: 0.2033 - accuracy: 0.9655 - val_loss: 0.1962 - val_accuracy: 0.9770\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 65s 847ms/step - loss: 0.1869 - accuracy: 0.9672 - val_loss: 0.1759 - val_accuracy: 0.9732\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 55s 716ms/step - loss: 0.1959 - accuracy: 0.9622 - val_loss: 0.1658 - val_accuracy: 0.9732\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 57s 743ms/step - loss: 0.2010 - accuracy: 0.9524 - val_loss: 0.1890 - val_accuracy: 0.9693\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 65s 847ms/step - loss: 0.1881 - accuracy: 0.9540 - val_loss: 0.1739 - val_accuracy: 0.9617\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 65s 855ms/step - loss: 0.1613 - accuracy: 0.9721 - val_loss: 0.1685 - val_accuracy: 0.9693\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 65s 851ms/step - loss: 0.1867 - accuracy: 0.9672 - val_loss: 0.1525 - val_accuracy: 0.9808\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 65s 846ms/step - loss: 0.1692 - accuracy: 0.9672 - val_loss: 0.1677 - val_accuracy: 0.9732\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 63s 824ms/step - loss: 0.1754 - accuracy: 0.9573 - val_loss: 0.1737 - val_accuracy: 0.9770\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 63s 826ms/step - loss: 0.1558 - accuracy: 0.9721 - val_loss: 0.1528 - val_accuracy: 0.9655\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 65s 851ms/step - loss: 0.1588 - accuracy: 0.9655 - val_loss: 0.1578 - val_accuracy: 0.9732\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 63s 823ms/step - loss: 0.1634 - accuracy: 0.9672 - val_loss: 0.1804 - val_accuracy: 0.9540\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 65s 856ms/step - loss: 0.1796 - accuracy: 0.9606 - val_loss: 0.1720 - val_accuracy: 0.9617\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 65s 855ms/step - loss: 0.1944 - accuracy: 0.9589 - val_loss: 0.1461 - val_accuracy: 0.9693\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 65s 845ms/step - loss: 0.1718 - accuracy: 0.9524 - val_loss: 0.1502 - val_accuracy: 0.9770\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 63s 820ms/step - loss: 0.1498 - accuracy: 0.9737 - val_loss: 0.1428 - val_accuracy: 0.9732\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 64s 835ms/step - loss: 0.1568 - accuracy: 0.9557 - val_loss: 0.1446 - val_accuracy: 0.9693\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 65s 853ms/step - loss: 0.1528 - accuracy: 0.9704 - val_loss: 0.1701 - val_accuracy: 0.9693\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 56s 725ms/step - loss: 0.1502 - accuracy: 0.9737 - val_loss: 0.1297 - val_accuracy: 0.9732\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 65s 853ms/step - loss: 0.1479 - accuracy: 0.9622 - val_loss: 0.1402 - val_accuracy: 0.9655\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 65s 847ms/step - loss: 0.1409 - accuracy: 0.9672 - val_loss: 0.1521 - val_accuracy: 0.9655\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 65s 841ms/step - loss: 0.1283 - accuracy: 0.9787 - val_loss: 0.1519 - val_accuracy: 0.9655\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 63s 821ms/step - loss: 0.1348 - accuracy: 0.9754 - val_loss: 0.1294 - val_accuracy: 0.9808\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 57s 747ms/step - loss: 0.1429 - accuracy: 0.9688 - val_loss: 0.1317 - val_accuracy: 0.9655\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 55s 715ms/step - loss: 0.1451 - accuracy: 0.9655 - val_loss: 0.1300 - val_accuracy: 0.9693\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 65s 850ms/step - loss: 0.1454 - accuracy: 0.9639 - val_loss: 0.1291 - val_accuracy: 0.9732\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 55s 716ms/step - loss: 0.1304 - accuracy: 0.9737 - val_loss: 0.1821 - val_accuracy: 0.9540\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 65s 850ms/step - loss: 0.1401 - accuracy: 0.9688 - val_loss: 0.1227 - val_accuracy: 0.9655\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 66s 854ms/step - loss: 0.1447 - accuracy: 0.9655 - val_loss: 0.1168 - val_accuracy: 0.9847\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 65s 854ms/step - loss: 0.1284 - accuracy: 0.9622 - val_loss: 0.1203 - val_accuracy: 0.9770\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 64s 835ms/step - loss: 0.1200 - accuracy: 0.9704 - val_loss: 0.1123 - val_accuracy: 0.9770\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 55s 722ms/step - loss: 0.1090 - accuracy: 0.9803 - val_loss: 0.1038 - val_accuracy: 0.9847\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 63s 815ms/step - loss: 0.1049 - accuracy: 0.9836 - val_loss: 0.1103 - val_accuracy: 0.9770\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 65s 848ms/step - loss: 0.1139 - accuracy: 0.9770 - val_loss: 0.1365 - val_accuracy: 0.9655\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 63s 822ms/step - loss: 0.1284 - accuracy: 0.9655 - val_loss: 0.1128 - val_accuracy: 0.9732\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 55s 717ms/step - loss: 0.1142 - accuracy: 0.9688 - val_loss: 0.0883 - val_accuracy: 0.9885\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 66s 858ms/step - loss: 0.1217 - accuracy: 0.9721 - val_loss: 0.0952 - val_accuracy: 0.9770\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 55s 721ms/step - loss: 0.1152 - accuracy: 0.9655 - val_loss: 0.1026 - val_accuracy: 0.9808\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 65s 852ms/step - loss: 0.1089 - accuracy: 0.9704 - val_loss: 0.0831 - val_accuracy: 0.9808\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 61s 795ms/step - loss: 0.1036 - accuracy: 0.9770 - val_loss: 0.0946 - val_accuracy: 0.9770\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 63s 823ms/step - loss: 0.0972 - accuracy: 0.9852 - val_loss: 0.0756 - val_accuracy: 0.9847\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 56s 734ms/step - loss: 0.1183 - accuracy: 0.9688 - val_loss: 0.0982 - val_accuracy: 0.9732\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 56s 720ms/step - loss: 0.1129 - accuracy: 0.9770 - val_loss: 0.0837 - val_accuracy: 0.9808\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 57s 749ms/step - loss: 0.0969 - accuracy: 0.9754 - val_loss: 0.0783 - val_accuracy: 0.9923\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 56s 733ms/step - loss: 0.1101 - accuracy: 0.9721 - val_loss: 0.0876 - val_accuracy: 0.9885\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 64s 834ms/step - loss: 0.0805 - accuracy: 0.9852 - val_loss: 0.0722 - val_accuracy: 0.9808\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 55s 718ms/step - loss: 0.0985 - accuracy: 0.9803 - val_loss: 0.1359 - val_accuracy: 0.9617\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 65s 848ms/step - loss: 0.1322 - accuracy: 0.9589 - val_loss: 0.1206 - val_accuracy: 0.9617\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 65s 839ms/step - loss: 0.0973 - accuracy: 0.9737 - val_loss: 0.0918 - val_accuracy: 0.9770\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 64s 827ms/step - loss: 0.0922 - accuracy: 0.9754 - val_loss: 0.0616 - val_accuracy: 0.9923\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 57s 744ms/step - loss: 0.0840 - accuracy: 0.9803 - val_loss: 0.0718 - val_accuracy: 0.9770\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 64s 837ms/step - loss: 0.0915 - accuracy: 0.9770 - val_loss: 0.0956 - val_accuracy: 0.9732\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 66s 858ms/step - loss: 0.0878 - accuracy: 0.9787 - val_loss: 0.0629 - val_accuracy: 0.9847\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 57s 739ms/step - loss: 0.0892 - accuracy: 0.9836 - val_loss: 0.0763 - val_accuracy: 0.9885\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 55s 713ms/step - loss: 0.0783 - accuracy: 0.9885 - val_loss: 0.0910 - val_accuracy: 0.9808\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 65s 845ms/step - loss: 0.0719 - accuracy: 0.9869 - val_loss: 0.0723 - val_accuracy: 0.9847\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 65s 840ms/step - loss: 0.0862 - accuracy: 0.9819 - val_loss: 0.0874 - val_accuracy: 0.9808\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 64s 842ms/step - loss: 0.0784 - accuracy: 0.9852 - val_loss: 0.0958 - val_accuracy: 0.9732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(final_model, '/content/drive/MyDrive/0-myComputerVisionProjects/my_saved_siamese')"
      ],
      "metadata": {
        "id": "i9y3GcWu46Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model for prediction\n",
        "loaded_model = tf.saved_model.load('/content/drive/MyDrive/0-myComputerVisionProjects/my_saved_siamese')"
      ],
      "metadata": {
        "id": "i1lk9o-R5ZZz"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loaded = load_model('/content/final_model_weights.h5')"
      ],
      "metadata": {
        "id": "I7UpY7qu_avA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height,width = size,size\n",
        "image1 = cv2.imread('/content/bela1.png')\n",
        "image2 = cv2.imread('/content/bela2.png')\n",
        "\n",
        "image1 = cv2.resize(image1,(height,width))\n",
        "image2 = cv2.resize(image2,(height,width))\n",
        "\n",
        "image1 = image1.astype('float32') / 255.0\n",
        "image2 = image2.astype('float32') / 255.0\n",
        "\n",
        "image1 = np.expand_dims(image1, axis=0)\n",
        "image2 = np.expand_dims(image2, axis=0)"
      ],
      "metadata": {
        "id": "5PxSlZAa5aEn"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = final_model.predict([image1,image2])[0][0]"
      ],
      "metadata": {
        "id": "hWIdJ0vkmYuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc317cc-4fed-4fb7-c619-53b9cdfdb95e"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPm98_u6OWvT",
        "outputId": "2ccfba04-11b6-463b-f0c0-de2d35ccb1d0"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9527568"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    }
  ]
}